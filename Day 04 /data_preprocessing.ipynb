{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5cdbb1",
   "metadata": {},
   "source": [
    "# Module 3: Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873212b6",
   "metadata": {},
   "source": [
    "This module covers essential techniques to clean, preprocess, and transform raw data into features suitable for machine learning algorithms. We'll also explore privacy-preserving methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acc9f6",
   "metadata": {},
   "source": [
    "## 1. Data Analysis and Preprocessing Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e9c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'Age': [25, 27, None, 22, 28],\n",
    "    'Salary': [50000, 54000, 58000, None, 52000],\n",
    "    'City': ['Lahore', 'Karachi', 'Lahore', 'Islamabad', None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3e55c6",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c314aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handling missing values\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n",
    "df['City'].fillna('Unknown', inplace=True)\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5a4b9",
   "metadata": {},
   "source": [
    "## 3. Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c1581",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert categorical 'City' into numerical using one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['City'])\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec2f548",
   "metadata": {},
   "source": [
    "## 4. Detecting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be70739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.boxplot(x=df['Salary'])\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631d0363",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c53ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create new feature: 'Salary per Age'\n",
    "df['Salary_per_Age'] = df['Salary'] / df['Age']\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e6b63b",
   "metadata": {},
   "source": [
    "## 6. Dimensionality Reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89fe163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(scaled)\n",
    "pca_data[:5]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6669149",
   "metadata": {},
   "source": [
    "## 7. Privacy-Preserving Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d88031",
   "metadata": {},
   "source": [
    "\n",
    "- **Anonymization**: Removing or encrypting identifiers (e.g., names, IDs).\n",
    "- **Differential Privacy**: Adding noise to data or query results to prevent individual data leakage.\n",
    "- **Example**: Adding noise to Salary.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05666383",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Add Laplace noise to Salary\n",
    "epsilon = 1.0\n",
    "sensitivity = df['Salary'].max() - df['Salary'].min()\n",
    "noise = np.random.laplace(loc=0.0, scale=sensitivity/epsilon, size=df.shape[0])\n",
    "df['Noisy_Salary'] = df['Salary'] + noise\n",
    "df\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
